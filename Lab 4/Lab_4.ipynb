{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Diana Kim ADA-2403M**"
      ],
      "metadata": {
        "id": "LQCGyPLcvnNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Практическая работа №4**\n",
        "**Тема:** Оптимизация параллельного кода на GPU с использованием различных типов памяти.\n",
        "\n",
        "**Цель работы:** Изучение и использование различных типов памяти CUDA  (глобальная, разделяемая, локальная) для оптимизации параллельных вычислений на GPU."
      ],
      "metadata": {
        "id": "bSvVF9Vqvsv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SikwE48ivK_0",
        "outputId": "5fe31d2a-537e-492a-f60b-496a2e1ad990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan  9 09:36:40 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICV7pjjpwv0a",
        "outputId": "f7c6fd4a-6b69-4940-b8fd-594effa233c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Лабораторная работа разделена на 3 части***"
      ],
      "metadata": {
        "id": "C3Tv0-o4MGEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1 часть. Редукция суммы, здесь только global memory**\n",
        "\n",
        "Задача этой части заключается в реализации наивного варианта параллельной редукции суммы элементов массива на GPU с использованием только глобальной памяти. Он используется как базовый эталон для последующего сравнения с оптимизированными решениями, использующими другие типы памяти\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8orEZgI_MSo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile part1.cu\n",
        "\n",
        "#include <cuda_runtime.h>        // для функций CUDA, которые мне надо\n",
        "#include <iostream>                  // ввод/вывод\n",
        "#include <ctime>        // для time()\n",
        "#include <cstdlib>        // для rand() и srand()\n",
        "\n",
        "using namespace std;                 // чтобы не писать std\n",
        "\n",
        "\n",
        "void cuda_ok(cudaError_t err, const char* msg) {          // функция для проверки ошибок CUDA\n",
        "    if (err != cudaSuccess) {                  // если есть ошибка\n",
        "        cout << \"CUDA error (\" << msg << \"): \"         // печатает место ошибки\n",
        "             << cudaGetErrorString(err) << endl;            // печатает текст ошибки\n",
        "        exit(1);                          // завершает программу\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_global(int* data, int* result, int n) {           // ядро суммирует элементы\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;            // считает индекс потока\n",
        "    if (idx < n) {                           // проверяет границы\n",
        "        atomicAdd(result, data[idx]);                // добавляет элемент в общую сумму\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int N = 1000000;                     // размер массива\n",
        "    int size = N * (int)sizeof(int);         // размер массива в байтах\n",
        "    int* h_data = new int[N];            // выделяет массив на CPU\n",
        "    int h_result = 0;                         // результат на CPU\n",
        "\n",
        "    srand((unsigned)time(0));           // запускает генератор случайных чисел\n",
        "\n",
        "    for (int i = 0; i < N; i++) {          // цикл по массиву\n",
        "        h_data[i] = rand() % 10;               // заполняет числами от 0 до 9\n",
        "    }\n",
        "\n",
        "    int* d_data = nullptr;                   // указатель на массив на GPU\n",
        "    int* d_result = nullptr;                     // указатель на сумму на GPU\n",
        "    cuda_ok(cudaMalloc((void**)&d_data, size), \"cudaMalloc d_data\");            // выделяет память под массив на GPU\n",
        "    cuda_ok(cudaMalloc((void**)&d_result, (int)sizeof(int)), \"cudaMalloc d_result\");                 // выделяет память под сумму на GPU\n",
        "    cuda_ok(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice), \"cudaMemcpy H->D data\");                  // копирует массив на GPU\n",
        "    cuda_ok(cudaMemset(d_result, 0, (int)sizeof(int)), \"cudaMemset d_result\");                    // обнуляет сумму на GPU\n",
        "\n",
        "    int blockSize = 256;                               // потоки в блоке\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;               // блоки в сетке\n",
        "    sum_global<<<numBlocks, blockSize>>>(d_data, d_result, N);            // запускает ядро\n",
        "    cuda_ok(cudaGetLastError(), \"kernel launch\");                // проверяет ошибку запуска ядра\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"cudaDeviceSynchronize\");        // ждёт завершения ядра и ловит ошибки выполнения\n",
        "    cuda_ok(cudaMemcpy(&h_result, d_result, (int)sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H result\");          // копирует сумму на CPU\n",
        "\n",
        "    cout << \"sum: \" << h_result << endl;             // выводит сумму\n",
        "\n",
        "    cuda_ok(cudaFree(d_data), \"cudaFree d_data\");            // освобождает память массива на GPU\n",
        "    cuda_ok(cudaFree(d_result), \"cudaFree d_result\");           // освобождает память суммы на GPU\n",
        "\n",
        "    delete[] h_data;                         // освобождает память на CPU\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZNVm5UAw5xD",
        "outputId": "4fdb205b-b509-4efb-d08a-820576d5ff53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting part1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part1.cu -o part1 -arch=compute_75 -code=sm_75"
      ],
      "metadata": {
        "id": "jldEULnG65mU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KRncw3i6-Mq",
        "outputId": "01753946-62bb-4047-888d-46911eb4bf82"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum: 4496561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2 часть. Редукция суммы, здесь глобальная память + локальная память**\n",
        "\n",
        "Задача этой части показать, что использование локальная память позволяет сократить число обращений к медленной глобальной памяти и повысить производительность по сравнению с вариантом, где используется только глобальная память"
      ],
      "metadata": {
        "id": "zppfL3kqOYJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile part2.cu\n",
        "\n",
        "#include <cuda_runtime.h>        // для функций CUDA, которые мне надо\n",
        "#include <iostream>                  // ввод/вывод\n",
        "#include <ctime>        // для time()\n",
        "#include <cstdlib>        // для rand() и srand()\n",
        "\n",
        "using namespace std;                 // чтобы не писать std\n",
        "\n",
        "\n",
        "void cuda_ok(cudaError_t err, const char* msg) {            // функция для проверки ошибок CUDA\n",
        "    if (err != cudaSuccess) {                         // если есть ошибка\n",
        "        cout << \"CUDA error (\" << msg << \"): \"             // печатает место ошибки\n",
        "             << cudaGetErrorString(err) << endl;              // печатает текст ошибки\n",
        "        exit(1);                               // завершает программу\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_shared(int* data, int* result, int n) {                  // ядро редукция с shared memory\n",
        "    __shared__ int sharedData[256];                // shared память на блок\n",
        "    int tid = threadIdx.x;                            // номер потока внутри блока\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;         // глобальный индекс элемента\n",
        "    if (idx < n) {                      // если индекс в пределах массива\n",
        "        sharedData[tid] = data[idx];           // кладёт элемент из global в shared\n",
        "    } else {                                             // иначе (если вышли за пределы)\n",
        "        sharedData[tid] = 0;                 // кладёт 0, чтобы не мешал сумме\n",
        "    }\n",
        "    __syncthreads();            // ждёт, пока все потоки запишут sharedData\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s /= 2) {           // уменьшает шаг редукции 128,64,32...\n",
        "        if (tid < s) {                               // только первая половина потоков работает\n",
        "            sharedData[tid] += sharedData[tid + s];              // складывает пары в shared памяти\n",
        "        }\n",
        "        __syncthreads();           // синхронизация после каждого шага\n",
        "    }\n",
        "    if (tid == 0) {                         // только поток 0 в блоке\n",
        "        atomicAdd(result, sharedData[0]);           // добавляет сумму блока в общую сумму global\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int N = 1000000;                        // размер массива\n",
        "    int size = N * (int)sizeof(int);             // размер массива в байтах\n",
        "    int* h_data = new int[N];              // выделяет массив на CPU\n",
        "    int h_result = 0;                   // результат на CPU\n",
        "    srand((unsigned)time(0));         // запускает генератор случайных чисел\n",
        "    for (int i = 0; i < N; i++) {               // цикл по массиву\n",
        "        h_data[i] = rand() % 10;                  // заполняет числами от 0 до 9\n",
        "    }\n",
        "\n",
        "    int* d_data = nullptr;                 // указатель на массив на GPU\n",
        "    int* d_result = nullptr;           // указатель на сумму на GPU\n",
        "\n",
        "    cuda_ok(cudaMalloc((void**)&d_data, size), \"cudaMalloc d_data\");                 // выделяет память массива на GPU\n",
        "    cuda_ok(cudaMalloc((void**)&d_result, (int)sizeof(int)), \"cudaMalloc d_result\"); // выделяет память суммы на GPU\n",
        "    cuda_ok(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice), \"cudaMemcpy H->D data\"); // копирует массив на GPU\n",
        "    cuda_ok(cudaMemset(d_result, 0, (int)sizeof(int)), \"cudaMemset d_result\");                  // обнуляет сумму на GPU\n",
        "\n",
        "    int blockSize = 256;                      // потоки в блоке ровно под sharedData[256]\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;            // количество блоков для покрытия всего массива\n",
        "    sum_shared<<<numBlocks, blockSize>>>(d_data, d_result, N);            // запускает ядро\n",
        "    cuda_ok(cudaGetLastError(), \"kernel launch\");           // проверяет ошибки запуска ядра\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"cudaDeviceSynchronize\");                 // ждёт завершения ядра\n",
        "    cuda_ok(cudaMemcpy(&h_result, d_result, (int)sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H result\");             // копирует сумму на CPU\n",
        "\n",
        "    cout << \"sum: \" << h_result << endl;           // выводит сумму\n",
        "\n",
        "    cuda_ok(cudaFree(d_data), \"cudaFree d_data\");                // освобождает память массива на GPU\n",
        "    cuda_ok(cudaFree(d_result), \"cudaFree d_result\");                 // освобождает память суммы на GPU\n",
        "\n",
        "    delete[] h_data;                   // освобождает память на CPU\n",
        "    return 0;                      // конец программы\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyn3E5xpHjE9",
        "outputId": "1590908d-e7d9-4297-8359-fed1ede02bef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing part2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part2.cu -o part2 -arch=compute_75 -code=sm_75"
      ],
      "metadata": {
        "id": "-SVm430fHmpq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbtU438qHqmi",
        "outputId": "db20bf4c-8b0f-4847-c746-d2ffea81ba28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum: 4498584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3 часть. Сортировка подмассивов с использованием локальной памяти**\n",
        "\n",
        "Задача этой части продемонстрировать использование локальной памяти для временных данных внутри одного потока и показать, что локальная память подходит для обработки небольших подмассивов, где важна простота и наглядность алгоритма, а не максимальная производительность."
      ],
      "metadata": {
        "id": "x_i1CIHvPfBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile part3.cu\n",
        "\n",
        "#include <cuda_runtime.h>        // для функций CUDA, которые мне надо\n",
        "#include <iostream>                  // ввод/вывод\n",
        "#include <ctime>        // для time()\n",
        "#include <cstdlib>        // для rand()\n",
        "\n",
        "using namespace std;            // чтобы не писать std::\n",
        "\n",
        "void cuda_ok(cudaError_t err, const char* msg) {                     // функция проверки ошибок CUDA\n",
        "    if (err != cudaSuccess) {                       // если ошибка не равна успеху\n",
        "        cout << \"CUDA error (\" << msg << \"): \" << cudaGetErrorString(err) << endl;             // печатает текст ошибки\n",
        "        exit(1);                      // завершает программу\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_global(int* data, int* result, int n) {               // ядро редукция только через global memory\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;            // вычисляет глобальный индекс потока\n",
        "    if (idx < n) {                   // проверяет границы массива\n",
        "        atomicAdd(result, data[idx]);                  // добавляет элемент к общей сумме\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_shared(int* data, int* result, int n) {                // ядро редукция через shared memory\n",
        "    __shared__ int sharedData[256];                      // выделяет shared память на блок 256 ints\n",
        "    int tid = threadIdx.x;                         // номер потока внутри блока\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;                   // глобальный индекс элемента\n",
        "    if (idx < n) {                        // если индекс не выходит за массив\n",
        "        sharedData[tid] = data[idx];                         // копирует элемент из global в shared\n",
        "    } else {                    // если индекс вышел за массив\n",
        "        sharedData[tid] = 0;                    // кладёт 0, чтобы не влиять на сумму\n",
        "    }\n",
        "    __syncthreads();                 // ждёт, пока все потоки запишут shared память\n",
        "    for (int s = blockDim.x / 2; s > 0; s /= 2) {                       // шаги редукции: 128,64,32...\n",
        "        if (tid < s) {               // работает только первая половина потоков\n",
        "            sharedData[tid] += sharedData[tid + s];             // складывает значения в shared памяти\n",
        "        }\n",
        "        __syncthreads();             // синхронизирует потоки после каждого шага\n",
        "    }\n",
        "    if (tid == 0) {                     // только нулевой поток блока\n",
        "        atomicAdd(result, sharedData[0]);                       // добавляет сумму блока в общую сумму\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "float run_and_time_global(int* h_data, int n, int& out_sum) {                  // функция запуска и замера времени для global версии\n",
        "    int size = n * (int)sizeof(int);                 // считает размер массива в байтах\n",
        "    int* d_data = nullptr;                    // указатель на массив на GPU\n",
        "    int* d_result = nullptr;                             // указатель на сумму на GPU\n",
        "    cudaEvent_t start, stop;              // переменные для событий CUDA (таймер)\n",
        "    int h_result = 0;                            // локальная переменная результата на CPU\n",
        "\n",
        "    cuda_ok(cudaMalloc((void**)&d_data, size), \"cudaMalloc d_data (global)\");             // выделяет память под массив на GPU\n",
        "    cuda_ok(cudaMalloc((void**)&d_result, (int)sizeof(int)), \"cudaMalloc d_result (global)\");              // выделяет память под сумму на GPU\n",
        "    cuda_ok(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice), \"cudaMemcpy H->D data (global)\");            // копирует массив на GPU\n",
        "    cuda_ok(cudaMemset(d_result, 0, (int)sizeof(int)), \"cudaMemset d_result (global)\");             // обнуляет сумму на GPU\n",
        "\n",
        "    cuda_ok(cudaEventCreate(&start), \"cudaEventCreate start (global)\");         // создаёт событие начала\n",
        "    cuda_ok(cudaEventCreate(&stop), \"cudaEventCreate stop (global)\");               // создаёт событие конца\n",
        "\n",
        "    int blockSize = 256;                  // фиксируем размер блока как 256 потоков\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;          // считает количество блоков\n",
        "    cuda_ok(cudaEventRecord(start), \"cudaEventRecord start (global)\");           // ставит старт таймера\n",
        "    sum_global<<<numBlocks, blockSize>>>(d_data, d_result, n);             // запускает ядро global версии\n",
        "    cuda_ok(cudaGetLastError(), \"kernel launch (global)\");             // проверяет ошибку запуска ядра\n",
        "    cuda_ok(cudaEventRecord(stop), \"cudaEventRecord stop (global)\");                  // ставит стоп таймера\n",
        "    cuda_ok(cudaEventSynchronize(stop), \"cudaEventSynchronize stop (global)\");               // ждёт завершения и таймера и ядра\n",
        "\n",
        "    float ms = 0.0f;              // переменная для времени в миллисекундах\n",
        "    cuda_ok(cudaEventElapsedTime(&ms, start, stop), \"cudaEventElapsedTime (global)\");               // считает время между началом и концом\n",
        "\n",
        "    cuda_ok(cudaMemcpy(&h_result, d_result, (int)sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H result (global)\");       // копирует сумму на CPU\n",
        "    out_sum = h_result;               // записывает сумму наружу\n",
        "\n",
        "    cuda_ok(cudaEventDestroy(start), \"cudaEventDestroy start (global)\");                // удаляет событие начала\n",
        "    cuda_ok(cudaEventDestroy(stop), \"cudaEventDestroy stop (global)\");             // удаляет событие конца\n",
        "    cuda_ok(cudaFree(d_data), \"cudaFree d_data (global)\");                               // освобождает массив на GPU\n",
        "    cuda_ok(cudaFree(d_result), \"cudaFree d_result (global)\");                          // освобождает сумму на GPU\n",
        "\n",
        "    return ms;                                // возвращает время в миллисекундах\n",
        "}\n",
        "\n",
        "\n",
        "float run_and_time_shared(int* h_data, int n, int& out_sum) {                        // функция запуска и замера времени для shared версии\n",
        "    int size = n * (int)sizeof(int);                // считает размер массива в байтах\n",
        "    int* d_data = nullptr;                  // указатель на массив на GPU\n",
        "    int* d_result = nullptr;                         // указатель на сумму на GPU\n",
        "    cudaEvent_t start, stop;                // переменные для событий CUDA\n",
        "    int h_result = 0;                           // локальная переменная результата на CPU\n",
        "\n",
        "    cuda_ok(cudaMalloc((void**)&d_data, size), \"cudaMalloc d_data (shared)\");                 // выделяет память под массив на GPU\n",
        "    cuda_ok(cudaMalloc((void**)&d_result, (int)sizeof(int)), \"cudaMalloc d_result (shared)\");                  // выделяет память под сумму на GPU\n",
        "    cuda_ok(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice), \"cudaMemcpy H->D data (shared)\");               // копирует массив на GPU\n",
        "    cuda_ok(cudaMemset(d_result, 0, (int)sizeof(int)), \"cudaMemset d_result (shared)\");                 // обнуляет сумму на GPU\n",
        "\n",
        "    cuda_ok(cudaEventCreate(&start), \"cudaEventCreate start (shared)\");                  // создаёт событие начала\n",
        "    cuda_ok(cudaEventCreate(&stop), \"cudaEventCreate stop (shared)\");           // создаёт событие конца\n",
        "\n",
        "    int blockSize = 256;                    // фиксируем размер блока как 256 потоков\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;                 // считает количество блоков\n",
        "\n",
        "    cuda_ok(cudaEventRecord(start), \"cudaEventRecord start (shared)\");               // ставит старт таймера\n",
        "    sum_shared<<<numBlocks, blockSize>>>(d_data, d_result, n);            // запускает ядро shared версии\n",
        "    cuda_ok(cudaGetLastError(), \"kernel launch (shared)\");                     // проверяет ошибку запуска ядра\n",
        "    cuda_ok(cudaEventRecord(stop), \"cudaEventRecord stop (shared)\");                   // ставит стоп таймера\n",
        "    cuda_ok(cudaEventSynchronize(stop), \"cudaEventSynchronize stop (shared)\");                    // ждёт завершения и таймера и ядра\n",
        "\n",
        "    float ms = 0.0f;                      // переменная для времени в миллисекундах\n",
        "    cuda_ok(cudaEventElapsedTime(&ms, start, stop), \"cudaEventElapsedTime (shared)\");                  // считает время между start и stop\n",
        "\n",
        "    cuda_ok(cudaMemcpy(&h_result, d_result, (int)sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H result (shared)\");       // копирует сумму на CPU\n",
        "    out_sum = h_result;             // записывает сумму наружу\n",
        "\n",
        "    cuda_ok(cudaEventDestroy(start), \"cudaEventDestroy start (shared)\");                 // удаляет событие начала\n",
        "    cuda_ok(cudaEventDestroy(stop), \"cudaEventDestroy stop (shared)\");                // удаляет событие конца\n",
        "    cuda_ok(cudaFree(d_data), \"cudaFree d_data (shared)\");                   // освобождает массив на GPU\n",
        "    cuda_ok(cudaFree(d_result), \"cudaFree d_result (shared)\");                          // освобождает сумму на GPU\n",
        "\n",
        "    return ms;                           // возвращает время в миллисекундах\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    srand((unsigned)time(0));              // инициализирует генератор случайных чисел\n",
        "    int sizes[3] = {10000, 100000, 1000000};                 // массив размеров для теста\n",
        "    cout << \"N | global ms | shared ms | sum_global | sum_shared\" << endl; // печатает заголовок таблицы\n",
        "\n",
        "    for (int t = 0; t < 3; t++) {                     // цикл по трем размерам\n",
        "        int N = sizes[t];                       // берёт текущий размер\n",
        "        int* h_data = new int[N];                      // выделяет массив на CPU\n",
        "\n",
        "        for (int i = 0; i < N; i++) {                  // заполняет массив\n",
        "            h_data[i] = rand() % 10;             // кладёт число от 0 до 9\n",
        "        }\n",
        "\n",
        "        int sum1 = 0;                 // сумма для global версии\n",
        "        int sum2 = 0;                     // сумма для shared версии\n",
        "\n",
        "        float ms_global = run_and_time_global(h_data, N, sum1);                // запускает global и получает время и сумму\n",
        "        float ms_shared = run_and_time_shared(h_data, N, sum2);                   // запускает shared и получает время и сумму\n",
        "\n",
        "        cout << N << \" | \" << ms_global << \" | \" << ms_shared << \" | \" << sum1 << \" | \" << sum2 << endl;           // печатает строку результатов\n",
        "\n",
        "        delete[] h_data;             // освобождает массив на CPU\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKOrCbJnLLl1",
        "outputId": "80dca46c-23fe-46fd-8ae3-a62e7d60ff1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing part3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part3.cu -o part3 -arch=compute_75 -code=sm_75"
      ],
      "metadata": {
        "id": "ewbNCeqiLmji"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHgo-mCPLpRi",
        "outputId": "81d883d6-4f5e-4dba-c04a-84eeac1c87b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N | global ms | shared ms | sum_global | sum_shared\n",
            "10000 | 0.1312 | 0.026304 | 45043 | 45043\n",
            "100000 | 0.010752 | 0.016096 | 450700 | 450700\n",
            "1000000 | 0.05328 | 0.100992 | 4499354 | 4499354\n"
          ]
        }
      ]
    }
  ]
}