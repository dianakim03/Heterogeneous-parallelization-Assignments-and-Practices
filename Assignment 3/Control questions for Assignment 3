Assignment 3

Контрольные вопросы 

1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?
В архитектуре CUDA используются глобальная, разделяемая, регистровая и локальная память. Регистры и разделяемая память являются самыми быстрыми, так как находятся близко к вычислительным блокам. Глобальная память имеет наибольшую задержку доступа, но позволяет хранить большие объёмы данных. Поэтому выбор типа памяти напрямую влияет на производительность программы.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?
Разделяемая память эффективна, когда несколько потоков одного блока многократно используют одни и те же данные. В таких ситуациях данные загружаются из глобальной памяти один раз и затем используются быстрее. Это снижает количество обращений к глобальной памяти и уменьшает задержки. Особенно полезно при редукциях и обработке блоков данных.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPUпрограммы?
Если потоки обращаются к соседним адресам памяти, доступ становится коалесцированным и выполняется быстрее. При некоалесцированном доступе GPU вынужден выполнять больше транзакций памяти. Это приводит к увеличению времени выполнения, даже если вычисления остаются одинаковыми. Поэтому порядок обращения к памяти играет ключевую роль.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?
Алгоритм может выполнять те же операции, но по-разному загружать подсистему памяти. Неэффективный доступ к глобальной памяти увеличивает задержки и снижает пропускную способность. В результате вычислительные блоки простаивают, ожидая данные. Это объясняет различие во времени выполнения при одинаковой логике.

5. Как размер блока потоков влияет на производительность CUDA-ядра?
Размер блока определяет, сколько потоков одновременно выполняется на одном мультипроцессоре. Слишком маленький блок может не полностью загружать GPU. Более подходящий размер блока позволяет лучше использовать вычислительные ресурсы и скрывать задержки памяти. Поэтому подбор block size важен для оптимальной производительности.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?
Варп — это группа из 32 потоков, которые выполняются синхронно. GPU обрабатывает инструкции именно на уровне варпов, а не отдельных потоков. Если потоки варпа выполняют разные ветки кода, возникает дивергенция. Это снижает эффективность выполнения и замедляет программу.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?
При выборе конфигурации учитываются размер данных, возможности GPU и характер вычислений. Важно подобрать block size, который хорошо загружает устройство и соответствует размеру варпа. Также имеет значение объём используемой памяти и количество регистров. Неправильная конфигурация может привести к снижению производительности.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
Во многих CUDA-программах основным узким местом является доступ к памяти, а не сами вычисления. Даже простой алгоритм может работать медленно из-за неэффективных обращений к глобальной памяти. Оптимизация шаблонов доступа часто даёт больший эффект, чем переписывание алгоритма. Поэтому анализ памяти является первым шагом оптимизации.
