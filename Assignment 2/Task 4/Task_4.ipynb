{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Задача 4. Сортировка на GPU с использованием CUDA**\n",
        "\n",
        "Diana Kim ADA-2403M\n",
        "\n",
        "**Практическое задание (25 баллов)**\n",
        "\n",
        "Реализуйте параллельную сортировку слиянием на GPU с использованием CUDA:\n",
        "*   разделите массив на подмассивы, каждый из которых обрабатывается отдельным блоком;\n",
        "*   выполните параллельное слияние отсортированных подмассивов;\n",
        "*   замерьте производительность для массивов размером 10 000 и 100 000 элементов.\n"
      ],
      "metadata": {
        "id": "lGC0IC954klp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подключение GPU и CUDA**"
      ],
      "metadata": {
        "id": "Y3NlQ3cq4G2A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lR2MtqFx1ZM",
        "outputId": "bc74b098-4cc2-49e5-add3-aaccaafd7fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 30 08:22:17 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjBAcKK1zEme",
        "outputId": "a9ff5f21-e02b-4fd9-d2a6-29cefc571c06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Практические задания**"
      ],
      "metadata": {
        "id": "PuGgvAGd4i8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Task4.cu\n",
        "\n",
        "#include <cuda_runtime.h>                 // для функций CUDA, которые мне надо\n",
        "#include <device_launch_parameters.h>               // подключает переменные threadIdx, blockIdx и параметры запуска ядра\n",
        "#include <iostream>                       // ввод/вывод\n",
        "#include <vector>                           // подключает vector\n",
        "#include <random>                         // для генерации случайных чисел\n",
        "#include <chrono>                          // для измерения времени выполнения\n",
        "#include <algorithm>                      // для алгоритмов, которые мне надо\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define CUDA_CHECK(call) do {                        /* делает проверку CUDA вызова */ \\\n",
        "    cudaError_t err = (call);                           /* сохраняет код ошибки */ \\\n",
        "    if (err != cudaSuccess) {                           /* проверяет, что ошибки нет */ \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err)                /* выводит текст ошибки */ \\\n",
        "             << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";                    /* выводит место ошибки */ \\\n",
        "        exit(1);                             /* завершает программу */ \\\n",
        "    }                                                        \\\n",
        "} while(0)\n",
        "\n",
        "static const int CHUNK = 256;                     // задает размер подмассива для одного блока\n",
        "static const int INF = 2147483647;            // задает большое число для заполнения хвоста\n",
        "\n",
        "\n",
        "__global__ void sortChunksBitonic(const int* in, int* out, int n) {           // сортирует каждый CHUNK параллельно по блокам\n",
        "    __shared__ int s[CHUNK];                    // создает shared память для быстрого доступа\n",
        "\n",
        "    int tid = threadIdx.x;                      // получает номер потока в блоке\n",
        "    int base = blockIdx.x * CHUNK;                      // вычисляет начало куска\n",
        "    int idx = base + tid;                            // вычисляет глобальный индекс\n",
        "\n",
        "    s[tid] = (idx < n) ? in[idx] : INF;                       // загружает данные или INF\n",
        "    __syncthreads();                     // синхронизирует потоки после загрузки\n",
        "\n",
        "    for (int k = 2; k <= CHUNK; k <<= 1) {                 // увеличивает размер сортируемых блоков\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {              // задает расстояние сравнения\n",
        "            int ixj = tid ^ j;                  // вычисляет партнера через XOR\n",
        "            if (ixj > tid) {              // делает сравнение один раз на пару\n",
        "                bool asc = ((tid & k) == 0);           // определяет направление сортировки\n",
        "                int a = s[tid];             // берет элемент a\n",
        "                int b = s[ixj];                // берет элемент b\n",
        "                if (asc) {                // сортирует по возрастанию\n",
        "                    if (a > b) { s[tid] = b; s[ixj] = a; }                   // меняет местами при необходимости\n",
        "                } else {                       // сортирует по убыванию\n",
        "                    if (a < b) { s[tid] = b; s[ixj] = a; }               // меняет местами при необходимости\n",
        "                }\n",
        "            }\n",
        "            __syncthreads();              // синхронизирует потоки после шага\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (idx < n) out[idx] = s[tid];             // записывает результат обратно в память\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void mergePass(const int* input, int* output, int n, int width) {                    // сливает пары отсортированных частей\n",
        "    int pairIdx = blockIdx.x;                  // получает номер пары\n",
        "    int start = pairIdx * (2 * width);                 // вычисляет начало пары\n",
        "    if (start >= n) return;                     // выходит, если за границей\n",
        "\n",
        "    int mid = (start + width < n) ? (start + width) : n;          // вычисляет середину\n",
        "    int end = (start + 2 * width < n) ? (start + 2 * width) : n;                // вычисляет конец\n",
        "\n",
        "    if (threadIdx.x == 0) {                 // делает слияние одним потоком\n",
        "        int i = start;                         // задает индекс левой части\n",
        "        int j = mid;                    // задает индекс правой части\n",
        "        int k = start;                    // задает индекс записи\n",
        "\n",
        "        while (i < mid && j < end) {                      // выполняет слияние пока есть элементы\n",
        "            if (input[i] <= input[j]) output[k++] = input[i++];           // записывает меньший элемент\n",
        "            else                      output[k++] = input[j++];                 // записывает другой элемент\n",
        "        }\n",
        "        while (i < mid) output[k++] = input[i++];          // дописывает остаток слева\n",
        "        while (j < end) output[k++] = input[j++];            // дописывает остаток справа\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "float gpuMergeSort(int* d_in, int* d_tmp, int n) {             // запускает сортировку на GPU и возвращает время\n",
        "    cudaEvent_t st, en;                        // создает события CUDA для таймера\n",
        "    CUDA_CHECK(cudaEventCreate(&st));              // создает событие старта\n",
        "    CUDA_CHECK(cudaEventCreate(&en));              // создает событие конца\n",
        "    CUDA_CHECK(cudaEventRecord(st));                // запускает таймер\n",
        "\n",
        "    int blocks = (n + CHUNK - 1) / CHUNK;              // вычисляет количество блоков для чанков\n",
        "\n",
        "    sortChunksBitonic<<<blocks, CHUNK>>>(d_in, d_tmp, n);                // сортирует чанки параллельно по блокам\n",
        "    CUDA_CHECK(cudaGetLastError());                  // проверяет запуск ядра\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());             // ждет завершения сортировки чанков\n",
        "\n",
        "    int* src = d_tmp;                 // задает источник как временный массив\n",
        "    int* dst = d_in;                    // задает приемник как исходный массив\n",
        "\n",
        "    for (int width = CHUNK; width < n; width *= 2) {            // увеличивает размер отсортированных прогонов\n",
        "        int pairs = (n + (2 * width) - 1) / (2 * width);                 // вычисляет количество пар для слияния\n",
        "        mergePass<<<pairs, 256>>>(src, dst, n, width);                  // выполняет слияние пар прогонов\n",
        "        CUDA_CHECK(cudaGetLastError());                 // проверяет запуск ядра\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());                  // ждет завершения слияния\n",
        "        std::swap(src, dst);                // меняет местами src и dst\n",
        "    }\n",
        "\n",
        "    if (src != d_in) {                                          // проверяет, где лежит итог\n",
        "        CUDA_CHECK(cudaMemcpy(d_in, src, n * sizeof(int), cudaMemcpyDeviceToDevice));               // копирует итог в d_in\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(en));                     // останавливает таймер\n",
        "    CUDA_CHECK(cudaEventSynchronize(en));                     // ждет окончания события\n",
        "    float ms = 0.0f;                               // создает переменную времени\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&ms, st, en));           // получает время в миллисекундах\n",
        "    CUDA_CHECK(cudaEventDestroy(st));                  // удаляет событие старта\n",
        "    CUDA_CHECK(cudaEventDestroy(en));              // удаляет событие конца\n",
        "\n",
        "    return ms;          // возвращает время\n",
        "}\n",
        "\n",
        "\n",
        "bool isSorted(const vector<int>& a) {                // проверяет, отсортирован ли массив\n",
        "    return std::is_sorted(a.begin(), a.end());              // возвращает результат проверки\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void runOne(int n) {                           // тест для конкретного размера\n",
        "    mt19937 rng(123);                             // задает генератор с фиксированным seed\n",
        "    uniform_int_distribution<int> dist(1, 1000000);             // задает диапазон чисел\n",
        "\n",
        "    vector<int> h(n);                     // создает массив на CPU\n",
        "    for (int i = 0; i < n; i++) h[i] = dist(rng);                  // заполняет массив случайными числами\n",
        "\n",
        "    int* d_in = nullptr;                    // создаёт указатель на вход GPU\n",
        "    int* d_tmp = nullptr;                      // создаёт указатель на временный GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_in, n * sizeof(int)));           // выделяет память на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_tmp, n * sizeof(int)));            // выделяет память на GPU\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_in, h.data(), n * sizeof(int), cudaMemcpyHostToDevice));             // копирует данные на GPU\n",
        "\n",
        "    float gpu_ms = gpuMergeSort(d_in, d_tmp, n);       // выполняет сортировку и получает время\n",
        "\n",
        "    vector<int> out(n);                     // создаёт массив результата на CPU\n",
        "    CUDA_CHECK(cudaMemcpy(out.data(), d_in, n * sizeof(int), cudaMemcpyDeviceToHost));          // копирует результат на CPU\n",
        "\n",
        "    cout << \"\\n N = \" << n << \" \\n\";            // выводит размер массива\n",
        "    cout << \"GPU merge time: \" << gpu_ms << \" ms\\n\";            // выводит время GPU сортировки\n",
        "    cout << \"sorted: \" << (isSorted(out) ? \"yes\" : \"no\") << \"\\n\";          // выводит корректность\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_in));                  // освобождает память d_in\n",
        "    CUDA_CHECK(cudaFree(d_tmp));                  // освобождает память d_tmp\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    CUDA_CHECK(cudaFree(0));                    // делает прогрев CUDA\n",
        "    runOne(10000);                           // запускает тест для 10000\n",
        "    runOne(100000);                    // запускает тест для 100000\n",
        "    return 0;                          // завершает программу\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbb4ugShHzo0",
        "outputId": "f6e454a6-e2e7-4cb9-8a13-697977e162aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Task4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Task4.cu -O2 -o Task4 -gencode arch=compute_75,code=sm_75\n",
        "!./Task4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1UEDh3yIJyc",
        "outputId": "bbcf4705-f5c2-4cd4-ebe6-77abbbfe356d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " N = 10000 \n",
            "GPU merge time: 5.2024 ms\n",
            "sorted: yes\n",
            "\n",
            " N = 100000 \n",
            "GPU merge time: 44.6086 ms\n",
            "sorted: yes\n"
          ]
        }
      ]
    }
  ]
}