{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Diana Kim ADA-2403M**"
      ],
      "metadata": {
        "id": "LQCGyPLcvnNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Практическая работа №5**\n",
        "**Тема:** Реализация параллельных структур данных на GPU.\n",
        "\n",
        "**Цель работы:**\n",
        "1. Освоить программирование параллельных структур данных с\n",
        "использованием CUDA.\n",
        "2. Реализовать параллельные структуры данных (например, параллельный\n",
        "стек и очередь).\n",
        "3. Провести исследование производительности реализованных структур\n",
        "данных."
      ],
      "metadata": {
        "id": "bSvVF9Vqvsv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SikwE48ivK_0",
        "outputId": "1d768abd-11e7-44c1-d4ff-0879cad3e01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 16 11:03:04 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICV7pjjpwv0a",
        "outputId": "bf6fd22f-25ee-48b4-b6b0-5712d95498b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Лабораторная работа разделена на 3 части***"
      ],
      "metadata": {
        "id": "C3Tv0-o4MGEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1 часть. Параллельный стек LIFO**\n",
        "\n",
        "Здесь мне необходимо реализовать параллельный стек LIFO на GPU с использованием глобальной памяти и атомарных операций, обеспечив корректное выполнение операций добавления и извлечения элементов при одновременной работе нескольких потоков.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8orEZgI_MSo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile part1.cu\n",
        "\n",
        "#include <cuda_runtime.h>        // для функций CUDA, которые мне надо\n",
        "#include <iostream>                  // ввод/вывод\n",
        "#include <cstdlib>                             // подключает exit()\n",
        "using namespace std;                           // чтобы не писать std\n",
        "\n",
        "\n",
        "\n",
        "void cuda_ok(cudaError_t err, const char* msg) {              // функция проверки ошибок CUDA\n",
        "    if (err != cudaSuccess) {                         // если произошла ошибка\n",
        "        cout << \"CUDA error (\" << msg << \"): \"           // печатает место ошибки\n",
        "             << cudaGetErrorString(err) << endl;              // печатает текст ошибки\n",
        "        exit(1);                                           // завершает программу\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "struct Stack {                    // структура стека\n",
        "    int* data;                // массив данных стека в GPU памяти\n",
        "    int top;                           // индекс вершины\n",
        "    int capacity;                // максимальная емкость стека\n",
        "\n",
        "    __device__ void init(int* buffer, int size) {                     // инициализация стека на GPU\n",
        "        data = buffer;                                     // запоминает указатель на буфер\n",
        "        top = -1;                                      // делает стек пустым\n",
        "        capacity = size;                                 // сохраняет ёмкость\n",
        "    }\n",
        "\n",
        "    __device__ bool push(int value) {              // кладёт элемент в стек\n",
        "        int pos = atomicAdd(&top, 1) + 1;                 // атомарно увеличивает top и получает позицию\n",
        "        if (pos < capacity) {                  // если место есть\n",
        "            data[pos] = value;                      // записывает значение в стек\n",
        "            return true;                     // сообщает успех\n",
        "        }\n",
        "        atomicSub(&top, 1);                         // откатывает top назад, если места нет\n",
        "        return false;                  // сообщает неуспех\n",
        "    }\n",
        "\n",
        "    __device__ bool pop(int* value) {                  // достаёт элемент из стека\n",
        "        int pos = atomicSub(&top, 1);                      // атомарно берёт текущий top и уменьшает его\n",
        "        if (pos >= 0) {                        // если стек не был пустым\n",
        "            *value = data[pos];                          // записывает извлечённое значение\n",
        "            return true;                 // сообщает успех\n",
        "        }\n",
        "        atomicAdd(&top, 1);                              // откатывает top назад, если был пустой\n",
        "        return false;                             // сообщает неуспех\n",
        "    }\n",
        "};\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__global__ void kernel_init(Stack* st, int* buffer, int cap) {                   // ядро для инициализации стека\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {                 // только один поток выполняет\n",
        "        st->init(buffer, cap);                        // инициализирует стек\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void kernel_push(Stack* st, int n_push, int* ok_push) {                // ядро для параллельных push\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;                         // вычисляет глобальный id потока\n",
        "    if (tid < n_push) {                                           // если поток входит в число push\n",
        "        bool ok = st->push(tid);                             // кладёт tid в стек\n",
        "        ok_push[tid] = ok ? 1 : 0;                             // сохраняет 1 если push успешен\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void kernel_pop(Stack* st, int n_pop, int* out, int* ok_pop) {                    // ядро для параллельных pop\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;                                 // вычисляет глобальный id потока\n",
        "    if (tid < n_pop) {                                                     // если поток входит в число pop\n",
        "        int val = -1;                                                  // создаёт переменную для значения\n",
        "        bool ok = st->pop(&val);                               // пытается достать значение из стека\n",
        "        out[tid] = val;                              // записывает извлечённое значение\n",
        "        ok_pop[tid] = ok ? 1 : 0;                        // сохраняет 1 если pop успешен\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void kernel_get_top(Stack* st, int* out_top) {                   // ядро чтобы прочитать top\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {                        // только один поток выполняет\n",
        "        out_top[0] = st->top;                          // копирует top в массив\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    const int CAP = 1024;                     // емкость стека\n",
        "    const int N_PUSH = 512;                      // сколько элементов кладем\n",
        "    const int N_POP  = 512;                        // сколько элементов достаем\n",
        "    int* d_buffer = nullptr;               // буфер данных стека на GPU\n",
        "    Stack* d_stack = nullptr;                         // объект стека на GPU\n",
        "    int* d_ok_push = nullptr;                  // массив успешности push на GPU\n",
        "    int* d_ok_pop  = nullptr;                   // массив извлечённых значений на GPU\n",
        "    int* d_top_val = nullptr;              // массив для top на GPU\n",
        "    int* d_out = nullptr;          // массив извлечённых значений на GPU\n",
        "\n",
        "    cuda_ok(cudaMalloc((void**)&d_buffer, CAP * (int)sizeof(int)), \"cudaMalloc d_buffer\");                // выделяет буфер стека\n",
        "    cuda_ok(cudaMalloc((void**)&d_stack, (int)sizeof(Stack)), \"cudaMalloc d_stack\");                       // выделяет память под Stack\n",
        "    cuda_ok(cudaMalloc((void**)&d_ok_push, N_PUSH * (int)sizeof(int)), \"cudaMalloc d_ok_push\");                   // выделяет ok_push\n",
        "    cuda_ok(cudaMalloc((void**)&d_ok_pop,  N_POP  * (int)sizeof(int)), \"cudaMalloc d_ok_pop\");                    // выделяет ok_pop\n",
        "    cuda_ok(cudaMalloc((void**)&d_out,     N_POP  * (int)sizeof(int)), \"cudaMalloc d_out\");                  // выделяет out\n",
        "    cuda_ok(cudaMalloc((void**)&d_top_val, (int)sizeof(int)), \"cudaMalloc d_top_val\");                          // выделяет top_val\n",
        "\n",
        "    kernel_init<<<1, 1>>>(d_stack, d_buffer, CAP);                     // запускает инициализацию стека\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_init launch\");                    // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_init sync\");                 // ждет завершения\n",
        "\n",
        "    int blockSize = 256;                                       // размер блока\n",
        "    int gridPush = (N_PUSH + blockSize - 1) / blockSize;                       // количество блоков для push\n",
        "    int gridPop  = (N_POP  + blockSize - 1) / blockSize;                        // количество блоков для pop\n",
        "\n",
        "    kernel_push<<<gridPush, blockSize>>>(d_stack, N_PUSH, d_ok_push);              // параллельно кладет значения\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_push launch\");                      // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_push sync\");                      // ждет завершения\n",
        "    kernel_pop<<<gridPop, blockSize>>>(d_stack, N_POP, d_out, d_ok_pop);                  // параллельно достает значения\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_pop launch\");                      // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_pop sync\");                            // ждет завершения\n",
        "    kernel_get_top<<<1, 1>>>(d_stack, d_top_val);                            // читает финальный top\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_get_top launch\");                        // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_get_top sync\");                       // ждет завершения\n",
        "\n",
        "    int* h_ok_push = new int[N_PUSH];                         // массив ok_push на CPU\n",
        "    int* h_ok_pop  = new int[N_POP];                                  // массив ok_pop на CPU\n",
        "    int* h_out     = new int[N_POP];                            // массив out на CPU\n",
        "    int  h_top     = 0;                               // переменная top на CPU\n",
        "    cuda_ok(cudaMemcpy(h_ok_push, d_ok_push, N_PUSH * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy ok_push\");                 // копирует ok_push\n",
        "    cuda_ok(cudaMemcpy(h_ok_pop,  d_ok_pop,  N_POP  * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy ok_pop\");                    // копирует ok_pop\n",
        "    cuda_ok(cudaMemcpy(h_out,     d_out,     N_POP  * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy out\");                  // копирует out\n",
        "    cuda_ok(cudaMemcpy(&h_top,    d_top_val, (int)sizeof(int),           cudaMemcpyDeviceToHost), \"copy top\");                      // копирует top\n",
        "\n",
        "    int push_success = 0;                         // счетчик успешных push\n",
        "    for (int i = 0; i < N_PUSH; i++) {                   // цикл по push\n",
        "        push_success += h_ok_push[i];                       // суммирует успехи push\n",
        "    }\n",
        "    int pop_success = 0;                              // счетчик успешных pop\n",
        "    for (int i = 0; i < N_POP; i++) {                       // цикл по pop\n",
        "        pop_success += h_ok_pop[i];                    // суммирует успехи pop\n",
        "    }\n",
        "\n",
        "    cout << \"Push success: \" << push_success << \" / \" << N_PUSH << endl;              // печатает сколько push прошло\n",
        "    cout << \"Pop  success: \" << pop_success  << \" / \" << N_POP  << endl;                // печатает сколько pop прошло\n",
        "    cout << \"Final top value: \" << h_top << endl;              // печатает финальный top\n",
        "    cout << \"10 popped values: \";\n",
        "    for (int i = 0; i < 10 && i < N_POP; i++) {                 // выводит первые 10 значений\n",
        "        cout << h_out[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    cuda_ok(cudaFree(d_buffer), \"cudaFree d_buffer\");                // освобождает буфер стека\n",
        "    cuda_ok(cudaFree(d_stack), \"cudaFree d_stack\");                      // освобождает Stack\n",
        "    cuda_ok(cudaFree(d_ok_push), \"cudaFree d_ok_push\");                // освобождает ok_push\n",
        "    cuda_ok(cudaFree(d_ok_pop), \"cudaFree d_ok_pop\");                    // освобождает ok_pop\n",
        "    cuda_ok(cudaFree(d_out), \"cudaFree d_out\");                        // освобождает out\n",
        "    cuda_ok(cudaFree(d_top_val), \"cudaFree d_top_val\");                   // освобождает top_val\n",
        "\n",
        "    delete[] h_ok_push;                             // освобождает ok_push на CPU\n",
        "    delete[] h_ok_pop;                                 // освобождает ok_pop на CPU\n",
        "    delete[] h_out;                               // освобождает out на CPU\n",
        "\n",
        "    return 0;                  // завершает программу\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5VncGerfe3b",
        "outputId": "0272ae23-534a-48d2-98b4-24337378311a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting part1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part1.cu -o part1 -arch=compute_75 -code=sm_75"
      ],
      "metadata": {
        "id": "x40Ra5H6fjdo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJn_Dk9bfoEY",
        "outputId": "54c84578-dacb-4308-afec-160627029029"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Push success: 512 / 512\n",
            "Pop  success: 512 / 512\n",
            "Final top value: -1\n",
            "10 popped values: 127 126 125 124 123 122 121 120 119 118 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2 часть. Параллельная очередь FIFO**\n",
        "\n",
        "А здесь мне необходимо реализовать параллельную очередь FIFO на GPU с использованием глобальной памяти и атомарных операций, обеспечив корректный порядок обработки данных и безопасный параллельный доступ нескольких потоков."
      ],
      "metadata": {
        "id": "zppfL3kqOYJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile part2.cu\n",
        "\n",
        "#include <cuda_runtime.h>        // для функций CUDA, которые мне надо\n",
        "#include <iostream>                  // ввод/вывод\n",
        "#include <cstdlib>                             // подключает exit()\n",
        "using namespace std;                           // чтобы не писать std\n",
        "\n",
        "\n",
        "\n",
        "void cuda_ok(cudaError_t err, const char* msg) {           // функция проверки ошибок CUDA\n",
        "    if (err != cudaSuccess) {                                 // если произошла ошибка\n",
        "        cout << \"CUDA error (\" << msg << \"): \"            // печатает место ошибки\n",
        "             << cudaGetErrorString(err) << endl;              // печатает текст ошибки\n",
        "        exit(1);                                // завершает программу\n",
        "    }\n",
        "}\n",
        "\n",
        "struct Queue {                                 // структура очереди\n",
        "    int* data;                                    // массив данных очереди в GPU памяти\n",
        "    int head;                           // индекс головы, то еть откуда читаем\n",
        "    int tail;                                 // индекс хвоста, то еть куда пишем\n",
        "    int capacity;                                // максимальная емкость очереди\n",
        "\n",
        "    __device__ void init(int* buffer, int size) {               // инициализация очереди на GPU\n",
        "        data = buffer;                                // запоминает указатель на буфер\n",
        "        head = 0;                                 // голова начинается с 0\n",
        "        tail = 0;                              // хвост начинается с 0\n",
        "        capacity = size;                            // сохраняет емкость\n",
        "    }\n",
        "    __device__ bool enqueue(int value) {                 // добавляет элемент в очередь\n",
        "        int pos = atomicAdd(&tail, 1);              // атомарно берет позицию и увеличивает tail\n",
        "        if (pos < capacity) {                 // если место в очереди есть\n",
        "            data[pos] = value;                 // записывает значение в очередь\n",
        "            return true;                          // сообщает успех\n",
        "        }\n",
        "        return false;                          // сообщает неуспех, очередь переполнена\n",
        "    }\n",
        "    __device__ bool dequeue(int* value) {                  // удаляет элемент из очереди\n",
        "        int pos = atomicAdd(&head, 1);                      // атомарно берёт позицию и увеличивает head\n",
        "        if (pos < tail) {                              // если элемент реально существует\n",
        "            *value = data[pos];                          // записывает извлечённое значение\n",
        "            return true;                           // сообщает успех\n",
        "        }\n",
        "        return false;                                // сообщает неуспех, очередь пуста\n",
        "    }\n",
        "};\n",
        "\n",
        "\n",
        "\n",
        "__global__ void kernel_init(Queue* q, int* buffer, int cap) {           // ядро инициализации очереди\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {                   // только один поток выполняет\n",
        "        q->init(buffer, cap);                              // инициализирует очередь\n",
        "    }\n",
        "}\n",
        "__global__ void kernel_enqueue(Queue* q, int n_enq, int* ok_enq) {       // ядро для параллельных enqueue\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;                  // вычисляет глобальный id потока\n",
        "    if (tid < n_enq) {                                  // если поток входит в число enqueue\n",
        "        bool ok = q->enqueue(tid);                             // добавляет tid в очередь\n",
        "        ok_enq[tid] = ok ? 1 : 0;                               // пишет 1 если успешно\n",
        "    }\n",
        "}\n",
        "__global__ void kernel_dequeue(Queue* q, int n_deq, int* out, int* ok_deq) {                 // ядро для параллельных dequeue\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;                             // вычисляет глобальный id потока\n",
        "    if (tid < n_deq) {                                                             // если поток входит в число dequeue\n",
        "        int val = -1;                                              // значение по умолчанию\n",
        "        bool ok = q->dequeue(&val);                                     // пытается достать значение\n",
        "        out[tid] = val;                                              // сохраняет значение\n",
        "        ok_deq[tid] = ok ? 1 : 0;                                    // пишет 1 если успешно\n",
        "    }\n",
        "}\n",
        "__global__ void kernel_get_head_tail(Queue* q, int* out_head, int* out_tail) {           // ядро чтения head и tail\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {                            // только один поток выполняет\n",
        "        out_head[0] = q->head;                                          // копирует head\n",
        "        out_tail[0] = q->tail;                                            // копирует tail\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    const int CAP = 1024;                          // емкость очереди\n",
        "    const int N_ENQ = 512;                              // сколько добавляем\n",
        "    const int N_DEQ = 512;                       // сколько извлекаем\n",
        "    int* d_buffer = nullptr;                           // буфер очереди на GPU\n",
        "    Queue* d_queue = nullptr;                   // объект очереди на GPU\n",
        "    int* d_ok_enq = nullptr;                   // массив успешности enqueue на GPU\n",
        "    int* d_ok_deq = nullptr;                     // массив успешности dequeue на GPU\n",
        "    int* d_out = nullptr;                 // массив извлеченных значений на GPU\n",
        "    int* d_head_val = nullptr;                            // массив для head на GPU\n",
        "    int* d_tail_val = nullptr;                          // массив для tail на GPU\n",
        "\n",
        "    cuda_ok(cudaMalloc((void**)&d_buffer, CAP * (int)sizeof(int)), \"cudaMalloc d_buffer\");               // выделяет буфер очереди\n",
        "    cuda_ok(cudaMalloc((void**)&d_queue, (int)sizeof(Queue)), \"cudaMalloc d_queue\");                  // выделяет память под Queue\n",
        "    cuda_ok(cudaMalloc((void**)&d_ok_enq, N_ENQ * (int)sizeof(int)), \"cudaMalloc d_ok_enq\");                 // выделяет ok_enq\n",
        "    cuda_ok(cudaMalloc((void**)&d_ok_deq, N_DEQ * (int)sizeof(int)), \"cudaMalloc d_ok_deq\");                       // выделяет ok_deq\n",
        "    cuda_ok(cudaMalloc((void**)&d_out, N_DEQ * (int)sizeof(int)), \"cudaMalloc d_out\");                         // выделяет out\n",
        "    cuda_ok(cudaMalloc((void**)&d_head_val, (int)sizeof(int)), \"cudaMalloc d_head_val\");                          // выделяет head_val\n",
        "    cuda_ok(cudaMalloc((void**)&d_tail_val, (int)sizeof(int)), \"cudaMalloc d_tail_val\");                         // выделяет tail_val\n",
        "\n",
        "    kernel_init<<<1, 1>>>(d_queue, d_buffer, CAP);                            // запускает инициализацию очереди\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_init launch\");                           // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_init sync\");                // ждет завершения\n",
        "    int blockSize = 256;                                               // размер блока\n",
        "    int gridEnq = (N_ENQ + blockSize - 1) / blockSize;                       // количество блоков для enqueue\n",
        "    int gridDeq = (N_DEQ + blockSize - 1) / blockSize;                             // количество блоков для dequeue\n",
        "    kernel_enqueue<<<gridEnq, blockSize>>>(d_queue, N_ENQ, d_ok_enq);                         // параллельно добавляет значения\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_enqueue launch\");                                          // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_enqueue sync\");                                      // ждет завершения\n",
        "    kernel_dequeue<<<gridDeq, blockSize>>>(d_queue, N_DEQ, d_out, d_ok_deq);                        // параллельно извлекает значения\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_dequeue launch\");                                      // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_dequeue sync\");                                     // ждет завершения\n",
        "    kernel_get_head_tail<<<1, 1>>>(d_queue, d_head_val, d_tail_val);                          // читает head и tail\n",
        "    cuda_ok(cudaGetLastError(), \"kernel_get_head_tail launch\");                                // проверяет запуск\n",
        "    cuda_ok(cudaDeviceSynchronize(), \"kernel_get_head_tail sync\");                         // ждет завершения\n",
        "\n",
        "    int* h_ok_enq = new int[N_ENQ];                   // ok_enq на CPU\n",
        "    int* h_ok_deq = new int[N_DEQ];               // ok_deq на CPU\n",
        "    int* h_out = new int[N_DEQ];                    // out на CPU\n",
        "    int h_head = 0;                            // head на CPU\n",
        "    int h_tail = 0;                               // tail на CPU\n",
        "    cuda_ok(cudaMemcpy(h_ok_enq, d_ok_enq, N_ENQ * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy ok_enq\");                 // копирует ok_enq\n",
        "    cuda_ok(cudaMemcpy(h_ok_deq, d_ok_deq, N_DEQ * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy ok_deq\");                 // копирует ok_deq\n",
        "    cuda_ok(cudaMemcpy(h_out, d_out, N_DEQ * (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy out\");                     // копирует out\n",
        "    cuda_ok(cudaMemcpy(&h_head, d_head_val, (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy head\");                       // копирует head\n",
        "    cuda_ok(cudaMemcpy(&h_tail, d_tail_val, (int)sizeof(int), cudaMemcpyDeviceToHost), \"copy tail\");                   // копирует tail\n",
        "\n",
        "    int enq_success = 0;                           // счетчик успешных enqueue\n",
        "    for (int i = 0; i < N_ENQ; i++) {                  // цикл по enqueue\n",
        "        enq_success += h_ok_enq[i];                // суммирует успехи enqueue\n",
        "    }\n",
        "    int deq_success = 0;                                // счетчик успешных dequeue\n",
        "    for (int i = 0; i < N_DEQ; i++) {               // цикл по dequeue\n",
        "        deq_success += h_ok_deq[i];                   // суммирует успехи dequeue\n",
        "    }\n",
        "\n",
        "    cout << \"enqueue success: \" << enq_success << \" / \" << N_ENQ << endl;                    // печатает успех enqueue\n",
        "    cout << \"dequeue success: \" << deq_success << \" / \" << N_DEQ << endl;                       // печатает успех dequeue\n",
        "    cout << \"final head: \" << h_head << \", final tail: \" << h_tail << endl;                    // печатает head и tail\n",
        "    cout << \"first 10 dequeued values: \";\n",
        "    for (int i = 0; i < 10 && i < N_DEQ; i++) {                                     // выводит первые 10 значений\n",
        "        cout << h_out[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    cuda_ok(cudaFree(d_buffer), \"cudaFree d_buffer\");           // освобождает буфер\n",
        "    cuda_ok(cudaFree(d_queue), \"cudaFree d_queue\");                   // освобождает объект очереди\n",
        "    cuda_ok(cudaFree(d_ok_enq), \"cudaFree d_ok_enq\");                      // освобождает ok_enq\n",
        "    cuda_ok(cudaFree(d_ok_deq), \"cudaFree d_ok_deq\");                       // освобождает ok_deq\n",
        "    cuda_ok(cudaFree(d_out), \"cudaFree d_out\");                         // освобождает out\n",
        "    cuda_ok(cudaFree(d_head_val), \"cudaFree d_head_val\");                 // освобождает head_val\n",
        "    cuda_ok(cudaFree(d_tail_val), \"cudaFree d_tail_val\");                  // освобождает tail_val\n",
        "\n",
        "    delete[] h_ok_enq;                            // освобождает ok_enq на CPU\n",
        "    delete[] h_ok_deq;                             // освобождает ok_deq на CPU\n",
        "    delete[] h_out;                         // освобождает out на CPU\n",
        "\n",
        "    return 0;        // завершает программу\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORxC5Pjuk52y",
        "outputId": "edd5ed63-3d54-4c60-c476-2a4c6d20ad11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting part2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part2.cu -o part2 -arch=compute_75 -code=sm_75"
      ],
      "metadata": {
        "id": "WgS7hJqylJtO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhbJNaIHlNcr",
        "outputId": "a0a7e57c-7298-4252-f983-05b40bc031e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enqueue success: 512 / 512\n",
            "dequeue success: 512 / 512\n",
            "final head: 512, final tail: 512\n",
            "first 10 dequeued values: 256 257 258 259 260 261 262 263 264 265 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3 часть. Сравнение параллельного стека и очереди на GPU**\n",
        "\n",
        "В данной части проводится сравнение двух параллельных структур данных, реализованных на GPU: стека LIFO и очереди FIFO. Обе структуры используют глобальную память и атомарные операции для обеспечения корректного параллельного доступа нескольких потоков."
      ],
      "metadata": {
        "id": "5qhzJmBLpVWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сравнение принципов работы**\n",
        "\n",
        "Стек работает по принципу последним пришел, первым вышел. Все операции push и pop синхронизируются через атомарные операции над одной переменной top.\n",
        "\n",
        "Очередь же работает по принципу первым пришёл, первым вышел. Для этого используются две атомарные переменные head и tail, что делает логику более сложной по сравнению со стеком.\n",
        "\n",
        "**Корректность работы**\n",
        "\n",
        "В обоих случаях все операции добавления и извлечения элементов были выполнены успешно. Финальные значения управляющих индексов (top для стека, head и tail для очереди) подтверждают, что структуры данных находятся в корректном состоянии после завершения параллельных операций.\n",
        "\n",
        "**Производительность и сложность**\n",
        "\n",
        "Реализация стека является более простой и требует меньшего количества управляющих переменных. Очередь, в свою очередь, сложнее в реализации, так как требует синхронизации двух индексов. При большом количестве потоков обе структуры могут испытывать снижение производительности из-за частого использования атомарных операций.\n",
        "\n",
        "**Вывод**\n",
        "\n",
        "В результате сравнения можно сделать вывод, что стек проще в реализации и удобен для задач, где не важен порядок обработки данных. Очередь подходит для сценариев, где необходимо строго соблюдать порядок обработки элементов. Оба подхода демонстрируют основные принципы синхронизации и параллельного доступа к данным на GPU."
      ],
      "metadata": {
        "id": "lnOsNb4hpmOd"
      }
    }
  ]
}