{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Лабораторная работа №3**"
      ],
      "metadata": {
        "id": "lGC0IC954klp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diana Kim ADA-2403M"
      ],
      "metadata": {
        "id": "waHiDIYwRR6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Подключение GPU и CUDA**"
      ],
      "metadata": {
        "id": "Y3NlQ3cq4G2A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lR2MtqFx1ZM",
        "outputId": "5a725302-0a72-4054-8338-7f68c2cc8de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 29 19:54:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjBAcKK1zEme",
        "outputId": "845c202d-ffd2-4cb4-8fc5-a7a9bb538011"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Практические задания**"
      ],
      "metadata": {
        "id": "PuGgvAGd4i8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "создаю файл main.cu прямо в Colab"
      ],
      "metadata": {
        "id": "76POnhD7_iDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.cu\n",
        "#include <cuda_runtime.h>               // для функций CUDA, которые мне надо\n",
        "#include <device_launch_parameters.h>                 // подключает переменные threadIdx, blockIdx и параметры запуска ядра\n",
        "#include <iostream>                   // ввод/вывод\n",
        "#include <vector>                            // подключает контейнер vector для динамических массивов\n",
        "#include <random>                        // для генерации случайных чисел\n",
        "#include <chrono>                                 // для измерения времени выполнения\n",
        "#include <algorithm>                 // для алгоритмов, которые мне надо\n",
        "\n",
        "#define INF 2147483647               // используется как заполнитель для хвоста массива\n",
        "#define CUDA_CHECK(call) do {                                                     /* объявляет макрос для проверки ошибок */ \\\n",
        "    cudaError_t err = (call);                                                     /* вызывает CUDA-функцию и сохраняет код ошибки */ \\\n",
        "    if (err != cudaSuccess) {                                                     /* проверяет, что вызов завершился успешно */ \\\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err)                    /* выводит текст ошибки */ \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";               /* выводит файл и строку */ \\\n",
        "        std::exit(1);                                                             /* завершает программу с ошибкой */ \\\n",
        "    }                                                                             /* закрывает if */ \\\n",
        "} while(0)                                                                        /* делает макрос одной командой */\n",
        "\n",
        "static const int CHUNK = 256;                // задает размер подмассива на один блок\n",
        "\n",
        "\n",
        "\n",
        "// CPU Merge sort, ЗАДАНИЕ 4\n",
        "static void cpuMergeSort(std::vector<int>& a) {            // объявляет функцию последовательной сортировки слиянием на CPU\n",
        "    int n = (int)a.size();                                       // получает размер массива и приводит к int\n",
        "    std::vector<int> tmp(n);              // создаёт временный массив tmp такого же размера\n",
        "    for (int width = 1; width < n; width *= 2) {               // увеличивает размер отсортированных блоков\n",
        "        for (int i = 0; i < n; i += 2 * width) {                  // проходит по массиву парами блоков длины width\n",
        "            int l = i;                         // запоминает левую границу первой части\n",
        "            int m = std::min(i + width, n);                 // вычисляет границу между частями при этом не выходя за n\n",
        "            int r = std::min(i + 2 * width, n);                       // вычисляет правую границу второй части при этом не выходя за n\n",
        "            int p = l, q = m, k = l;                     // создает указатели p по левой части, q по правой, k куда писать\n",
        "            while (p < m && q < r) tmp[k++] = (a[p] <= a[q]) ? a[p++] : a[q++];         // сливает две части, берёт меньший элемент и записывает в tmp\n",
        "            while (p < m) tmp[k++] = a[p++];                     // дописывает остаток левой части, если он остался\n",
        "            while (q < r) tmp[k++] = a[q++];                     // дописывает остаток правой части, если он остался\n",
        "        }\n",
        "        a.swap(tmp);                  // меняет местами a и tmp\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// CPU Quick sort, ЗАДАНИЕ 4\n",
        "static void cpuQuickSort(std::vector<int>& a) {                  // объявляет функцию быстрой сортировки на CPU\n",
        "    std::sort(a.begin(), a.end());           // сортирует vector стандартной функцией\n",
        "}\n",
        "\n",
        "\n",
        "// CPU Heap sort, ЗАДАНИЕ 4\n",
        "static void cpuHeapSort(std::vector<int>& a) {                     // объявляет функцию пирамидальной сортировки на CPU\n",
        "    std::make_heap(a.begin(), a.end());                       // превращает массив в max heap\n",
        "    std::sort_heap(a.begin(), a.end());                       // извлекает элементы из кучи и получает отсортированный массив\n",
        "}\n",
        "\n",
        "\n",
        "// ЗАДАНИЕ 1\n",
        "__global__ void mergePass(const int* input, int* output, int n, int width) {           // объявляет CUDA ядро для слияния двух отсортированных частей\n",
        "    int pairIdx = blockIdx.x;                       // получает номер пары, которую обрабатывает блок\n",
        "    int start = pairIdx * (2 * width);                            // вычисляет стартовый индекс пары прогонов\n",
        "    if (start >= n) return;                               // выходит, если блок вышел за пределы массива\n",
        "\n",
        "    int mid = (start + width < n) ? (start + width) : n;                // вычисляет середину (конец первого прогона), ограничивая n\n",
        "    int end = (start + 2 * width < n) ? (start + 2 * width) : n;              // вычисляет конец второго прогона, ограничивая n\n",
        "\n",
        "    if (threadIdx.x == 0) {                 // заставляет выполнять слияние только нулевой поток блока\n",
        "        int i = start, j = mid, k = start;              // задает индексы, i по левому прогону, j по правому, k позиция записи\n",
        "        while (i < mid && j < end) {           // выполняет слияние пока в обоих прогонах есть элементы\n",
        "            if (input[i] <= input[j]) output[k++] = input[i++];              // если левый элемент меньше или равен, то записывает его\n",
        "            else                      output[k++] = input[j++];              // иначе записывает правый элемент\n",
        "        }\n",
        "        while (i < mid) output[k++] = input[i++];                 // дописывает остаток левого прогона\n",
        "        while (j < end) output[k++] = input[j++];               // дописывает остаток правого прогона\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// GPU Merge sort, ЗАДАНИЕ 1\n",
        "__global__ void sortChunksBitonic(const int* in, int* out, int n) {             // объявляет CUDA ядро где один блок сортирует один CHUNK\n",
        "    __shared__ int s[CHUNK];             // создает shared массив внутри блока для быстрой сортировки\n",
        "    int tid  = threadIdx.x;                          // получает номер потока внутри блока\n",
        "    int base = blockIdx.x * CHUNK;             // вычисляет начало куска для этого блока\n",
        "    int idx  = base + tid;                 // вычисляет глобальный индекс элемента массива\n",
        "    s[tid] = (idx < n) ? in[idx] : INF;            // записывает элемент в shared или INF, если idx вышел за n\n",
        "    __syncthreads();                     // синхронизирует потоки, чтобы shared заполнен полностью\n",
        "    for (int k = 2; k <= CHUNK; k <<= 1) {              // увеличивает размер битонного блока в 2 раза\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {                 // задает расстояние для сравнения элементов\n",
        "            int ixj = tid ^ j;                       // вычисляет индекс партнера для сравнения через XOR\n",
        "            if (ixj > tid) {                       // проверяет условие, чтобы сравнение выполнялось один раз на пару\n",
        "                bool asc = ((tid & k) == 0);                   // определяет направление сортировки, вверх или вниз\n",
        "                int a = s[tid], b = s[ixj];             // берет два сравниваемых значения из shared\n",
        "                if (asc) { if (a > b) { s[tid] = b; s[ixj] = a; } }               // если направление вверх и a>b, то меняет местами\n",
        "                else     { if (a < b) { s[tid] = b; s[ixj] = a; } }             // если направление вниз и a<b, то меняет местами\n",
        "            }\n",
        "            __syncthreads();             // синхронизирует потоки после каждого шага сравнения\n",
        "        }\n",
        "    }\n",
        "    if (idx < n) out[idx] = s[tid];                     // записывает отсортированное значение обратно в глобальную память\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// GPU Quick sort, ЗАДАНИЕ 2\n",
        "__device__ void insertionSort(int* a, int n) {                   // объявляет функцию сортировки вставками для device\n",
        "    for (int i = 1; i < n; i++) {                         // проходит по элементам начиная со второго\n",
        "        int key = a[i];                      // сохраняет текущий элемент как key\n",
        "        int j = i - 1;                      // устанавливает j на элемент слева от key\n",
        "        while (j >= 0 && a[j] > key) {                // двигает элементы вправо, пока они больше key\n",
        "            a[j + 1] = a[j];                     // сдвигает элемент вправо на одну позицию\n",
        "            j--;                // уменьшает индекс j\n",
        "        }\n",
        "        a[j + 1] = key;           // вставляет key на правильное место\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sortChunksQuickSimple(const int* in, int* out, int n) {         // объявляет CUDA ядро для quick варианта, ЗАДАНИЕ 2\n",
        "    __shared__ int s[CHUNK];                  // создает shared массив для куска данных\n",
        "    int tid  = threadIdx.x;                        // получает номер потока в блоке\n",
        "    int base = blockIdx.x * CHUNK;                // вычисляет начало куска для этого блока\n",
        "    int idx  = base + tid;                            // вычисляет глобальный индекс элемента\n",
        "    s[tid] = (idx < n) ? in[idx] : INF;            // записывает элемент в shared или INF, если вышел за n\n",
        "    __syncthreads();               // синхронизирует потоки после загрузки\n",
        "    if (tid == 0) insertionSort(s, CHUNK);                         // запускает сортировку вставками одним потоком\n",
        "    __syncthreads();                           // синхронизирует потоки после сортировки\n",
        "    if (idx < n) out[idx] = s[tid];                               // записывает отсортированный кусок обратно в out\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "// GPU Heap sort, ЗАДАНИЕ 3\n",
        "__device__ void siftDown(int* a, int start, int end) {                 // объявляет функцию просеивания вниз для кучи\n",
        "    int root = start;                       // задает root как начальный индекс\n",
        "    while (true) {                  // запускает бесконечный цикл\n",
        "        int child = 2 * root + 1;                            // вычисляет индекс левого ребенка\n",
        "        if (child >= end) return;                     // выходит за груницу кучи, если детей нет\n",
        "        int swapIdx = root;                     // задает swapIdx как root, кандидат на обмен\n",
        "        if (a[swapIdx] < a[child]) swapIdx = child;                  // выбирает большего из root и левого ребенка\n",
        "        if (child + 1 < end && a[swapIdx] < a[child + 1]) swapIdx = child + 1;             // сравнивает еще и с правым ребенком\n",
        "\n",
        "        if (swapIdx == root) return;                       // выходит, если обмен не нужен\n",
        "        int t = a[root]; a[root] = a[swapIdx]; a[swapIdx] = t;            // меняет местами root и выбранного ребенка\n",
        "        root = swapIdx;                 // продолжает просеивание с новой позиции root\n",
        "    }\n",
        "}\n",
        "\n",
        "__device__ void heapSortChunk(int* a, int n) {                       // объявляет heapsort для одного чанка, ЗАДАНИЕ 3\n",
        "    for (int i = n / 2 - 1; i >= 0; --i) siftDown(a, i, n);               // строит max heap, просеивая все внутренние узлы\n",
        "    for (int end = n - 1; end > 0; --end) {                                     // извлекает максимум, уменьшая размер кучи\n",
        "        int t = a[0]; a[0] = a[end]; a[end] = t;                    // меняет местами первый и последний элемент кучи\n",
        "        siftDown(a, 0, end);                                   // восстанавливает свойство кучи для уменьшенной кучи\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sortChunksHeapSimple(const int* in, int* out, int n) {          // объявляет CUDA ядро heapsort на чанках, ЗАДАНИЕ 3\n",
        "    __shared__ int s[CHUNK];                  // создаёт shared массив для данных блока\n",
        "    int tid  = threadIdx.x;                            // получает номер потока в блоке\n",
        "    int base = blockIdx.x * CHUNK;                      // вычисляет начало куска\n",
        "    int idx  = base + tid;                           // вычисляет глобальный индекс\n",
        "    s[tid] = (idx < n) ? in[idx] : INF;                         // загружает данные в shared или INF, если вышел за n\n",
        "    __syncthreads();                             // синхронизирует потоки после загрузки\n",
        "    if (tid == 0) heapSortChunk(s, CHUNK);                // запускает heapsort одним потоком для простоты\n",
        "    __syncthreads();                                              // синхронизирует потоки после сортировки\n",
        "    if (idx < n) out[idx] = s[tid];                     // записывает отсортированные данные обратно в out\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// GPU pipeline\n",
        "static float gpuSortPipeline(int* d_in, int* d_tmp, int n, int mode) {               // объявляет функцию, которая запускает нужную GPU сортировку\n",
        "    // mode: 0=merge, 1=quick, 2=heap                           // поясняет значения параметра mode\n",
        "    cudaEvent_t st, en;                             // объявляет CUDA-события для измерения времени\n",
        "    CUDA_CHECK(cudaEventCreate(&st));                        // создает событие начала\n",
        "    CUDA_CHECK(cudaEventCreate(&en));                       // создает событие конца\n",
        "    CUDA_CHECK(cudaEventRecord(st));                        // записывает событие старта таймера\n",
        "    int blocks = (n + CHUNK - 1) / CHUNK;                      // вычисляет количество блоков для обработки всех элементов\n",
        "    if (mode == 0)      sortChunksBitonic<<<blocks, CHUNK>>>(d_in, d_tmp, n);               // запускает сортировку чанков битоником\n",
        "    else if (mode == 1) sortChunksQuickSimple<<<blocks, CHUNK>>>(d_in, d_tmp, n);                         // запускает сортировку чанков quick вариантом\n",
        "    else               sortChunksHeapSimple<<<blocks, CHUNK>>>(d_in, d_tmp, n);                         // запускает сортировку чанков heapsort вариантом\n",
        "    CUDA_CHECK(cudaGetLastError());                           // проверяет ошибки запуска CUDA-ядра\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());                               // ждет завершения сортировки чанков\n",
        "    int *src = d_tmp, *dst = d_in;                        // задает указатели src источник, dst приемник\n",
        "\n",
        "    for (int width = CHUNK; width < n; width *= 2) {                        // увеличивает размер отсортированных прогонов в 2 раза\n",
        "        int pairs = (n + (2 * width) - 1) / (2 * width);                       // вычисляет количество пар для слияния на этом шаге\n",
        "        mergePass<<<pairs, 256>>>(src, dst, n, width);                // запускает слияние пар прогонов\n",
        "        CUDA_CHECK(cudaGetLastError());                              // проверяет ошибки запуска mergePass\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());                          // ждет завершения mergePass\n",
        "        std::swap(src, dst);               // меняет местами src и dst для следующего шага\n",
        "    }\n",
        "\n",
        "    if (src != d_in) {                    // проверяет, что итог лежит не в d_in\n",
        "        CUDA_CHECK(cudaMemcpy(d_in, src, n * sizeof(int), cudaMemcpyDeviceToDevice));             // копирует итог в d_in, если нужно\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(en));                       // записывает событие окончания таймера\n",
        "    CUDA_CHECK(cudaEventSynchronize(en));              // ждет завершения события en\n",
        "    float ms = 0.f;                             // создает переменную для времени в миллисекундах\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&ms, st, en));                    // вычисляет время между st и en\n",
        "    CUDA_CHECK(cudaEventDestroy(st));                    // удаляет событие st\n",
        "    CUDA_CHECK(cudaEventDestroy(en));                       // удаляет событие en\n",
        "    return ms;                               // возвращает измеренное время GPU сортировки\n",
        "}\n",
        "\n",
        "static float gpuMergeSort(int* d_in, int* d_tmp, int n) { return gpuSortPipeline(d_in, d_tmp, n, 0); }              // вызывает GPU merge sort через общий конвейер, ЗАДАНИЕ 1\n",
        "static float gpuQuickSort(int* d_in, int* d_tmp, int n) { return gpuSortPipeline(d_in, d_tmp, n, 1); }                  // вызывает GPU quick sort через общий конвейер, ЗАДАНИЕ 2\n",
        "static float gpuHeapSort (int* d_in, int* d_tmp, int n) { return gpuSortPipeline(d_in, d_tmp, n, 2); }              // вызывает GPU heap sort через общий конвейер, ЗАДАНИЕ 3\n",
        "\n",
        "\n",
        "\n",
        "static double timeCpu(void(*fn)(std::vector<int>&), const std::vector<int>& input) {             // объявляет функцию измерения времени CPU сортировки, ЗАДАНИЕ 4\n",
        "    std::vector<int> a = input;                                      // копирует входной массив, чтобы не портить оригинал\n",
        "    auto t0 = std::chrono::high_resolution_clock::now();                // запоминает время начала\n",
        "    fn(a);                                    // вызывает переданную CPU сортировку\n",
        "    auto t1 = std::chrono::high_resolution_clock::now();                 // запоминает время конца\n",
        "    if (!std::is_sorted(a.begin(), a.end())) {                       // проверяет, что массив действительно отсортирован\n",
        "        std::cerr << \"CPU sort FAILED\\n\";                       // выводит сообщение об ошибке\n",
        "        std::exit(1);                                // завершает программу с ошибкой\n",
        "    }\n",
        "    std::chrono::duration<double, std::milli> ms = t1 - t0;                   // вычисляет длительность в миллисекундах\n",
        "    return ms.count();                                             // возвращает время CPU сортировки\n",
        "}\n",
        "static float timeGpu(float(*fn)(int*, int*, int), const std::vector<int>& input) {               // объявляет функцию измерения времени GPU сортировки, ЗАДАНИЕ 4\n",
        "    int n = (int)input.size();                                  // получает размер массива и приводит к int\n",
        "    int *d_in = nullptr, *d_tmp = nullptr;                             // объявляет указатели на память GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_in,  n * sizeof(int)));                           // выделяет память на GPU для входного массива\n",
        "    CUDA_CHECK(cudaMalloc(&d_tmp, n * sizeof(int)));                          // выделяет память на GPU для временного массива\n",
        "    CUDA_CHECK(cudaMemcpy(d_in, input.data(), n * sizeof(int), cudaMemcpyHostToDevice));         // копирует данные с CPU на GPU\n",
        "    float ms = fn(d_in, d_tmp, n);                   // запускает выбранную GPU сортировку и получает время\n",
        "    std::vector<int> out(n);                                        // создает массив out для результата на CPU\n",
        "    CUDA_CHECK(cudaMemcpy(out.data(), d_in, n * sizeof(int), cudaMemcpyDeviceToHost));           // копирует результат с GPU обратно на CPU\n",
        "    if (!std::is_sorted(out.begin(), out.end())) {                // проверяет, что результат отсортирован\n",
        "        std::cerr << \"GPU sort FAILED\\n\";                       // выводит сообщение об ошибке\n",
        "        std::exit(1);                        // завершает программу с ошибкой\n",
        "    }\n",
        "    CUDA_CHECK(cudaFree(d_in));                    // освобождает память d_in на GPU\n",
        "    CUDA_CHECK(cudaFree(d_tmp));            // освобождает память d_tmp на GPU\n",
        "    return ms;                               // возвращает время GPU сортировки\n",
        "}\n",
        "\n",
        "static void runN(int n) {                // объявляет функцию запуска теста для конкретного размера n, ЗАДАНИЕ 4\n",
        "    std::mt19937 rng(123);                      // создает генератор случайных чисел с фиксированным seed\n",
        "    std::uniform_int_distribution<int> dist(0, 1000000);        // задает диапазон случайных чисел\n",
        "\n",
        "    std::vector<int> a(n);                  // создает массив a размера n\n",
        "    for (int i = 0; i < n; i++) a[i] = dist(rng);                     // заполняет массив случайными числами\n",
        "\n",
        "    std::cout << \"\\n N = \" << n << \" \\n\" << std::flush;               // выводит заголовок теста и сразу сбрасывает буфер\n",
        "\n",
        "    std::cout << \"CPU merge: \" << timeCpu(cpuMergeSort, a) << \" ms\\n\" << std::flush;       // измеряет и выводит время CPU merge sort\n",
        "    std::cout << \"CPU quick: \" << timeCpu(cpuQuickSort, a) << \" ms\\n\" << std::flush;             // измеряет и выводит время CPU quick sort\n",
        "    std::cout << \"CPU heap : \" << timeCpu(cpuHeapSort,  a) << \" ms\\n\" << std::flush;           // измеряет и выводит время CPU heap sort\n",
        "\n",
        "    CUDA_CHECK(cudaFree(0));        // выполняет прогрев GPU\n",
        "\n",
        "    std::cout << \"GPU merge: \" << timeGpu(gpuMergeSort, a) << \" ms\\n\" << std::flush;          // измеряет и выводит время GPU merge sort\n",
        "    std::cout << \"GPU quick: \" << timeGpu(gpuQuickSort, a) << \" ms\\n\" << std::flush;            // измеряет и выводит время GPU quick sort\n",
        "    std::cout << \"GPU heap : \" << timeGpu(gpuHeapSort,  a) << \" ms\\n\" << std::flush;         // измеряет и выводит время GPU heap sort\n",
        "}\n",
        "\n",
        "\n",
        "int main() {             // ЗАДАНИЕ 4\n",
        "    runN(10000);                            // запускает тест для массива из 10000 элементов\n",
        "    runN(100000);                      // запускает тест для массива из 100000 элементов\n",
        "    runN(1000000);                       // запускает тест для массива из 1000000 элементов\n",
        "    return 0;             // завершает программу успешно\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lDxmO1X-yrI",
        "outputId": "a0eec15f-dcc2-403e-8270-7174e449bdc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f app\n",
        "!nvcc main.cu -O2 -o app -gencode arch=compute_75,code=sm_75\n",
        "!./app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu_RhTgv6S4_",
        "outputId": "9194e24a-6714-4b04-8f8c-b3ec5f994ba7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " N = 10000 \n",
            "CPU merge: 1.69602 ms\n",
            "CPU quick: 0.601974 ms\n",
            "CPU heap : 1.08445 ms\n",
            "GPU merge: 5.31507 ms\n",
            "GPU quick: 7.2287 ms\n",
            "GPU heap : 5.57891 ms\n",
            "\n",
            " N = 100000 \n",
            "CPU merge: 11.6598 ms\n",
            "CPU quick: 7.34017 ms\n",
            "CPU heap : 13.5176 ms\n",
            "GPU merge: 44.6602 ms\n",
            "GPU quick: 50.5612 ms\n",
            "GPU heap : 45.9671 ms\n",
            "\n",
            " N = 1000000 \n",
            "CPU merge: 146.489 ms\n",
            "CPU quick: 94.6492 ms\n",
            "CPU heap : 179.177 ms\n",
            "GPU merge: 231.543 ms\n",
            "GPU quick: 190.517 ms\n",
            "GPU heap : 176.507 ms\n"
          ]
        }
      ]
    }
  ]
}