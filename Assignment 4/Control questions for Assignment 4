Контрольные вопросы к Assignment 4

1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?
Гибридные вычисления предполагают совместное использование CPU и GPU, где каждая архитектура выполняет те части задачи, для которых она наиболее эффективна. CPU обычно отвечает за управление, логику и последовательные операции, а GPU — за массовые параллельные вычисления. В отличие от чисто CPU- или GPU-решений, гибридный подход позволяет лучше использовать доступные аппаратные ресурсы.

2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?
Распределение между CPU и GPU оправдано для задач, в которых есть как управляющая логика, так и вычислительно интенсивные параллельные участки. Примерами являются обработка массивов, линейная алгебра, численное моделирование и анализ больших данных. CPU эффективно управляет потоками и памятью, а GPU ускоряет однотипные операции над большими объёмами данных.

3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?
При синхронной передаче CPU ожидает завершения копирования данных, прежде чем продолжить выполнение программы. Асинхронная передача позволяет инициировать копирование и параллельно выполнять другие операции. Таким образом, асинхронный подход уменьшает простои процессора и ускоряет общий ход программы.

4. Почему асинхронная передача данных может повысить производительность программы?
Асинхронная передача данных позволяет перекрывать вычисления и операции копирования памяти. Пока данные передаются между CPU и GPU, вычислительные блоки могут выполнять другую работу. Это снижает время простоя устройств и более эффективно использует вычислительные ресурсы системы.

5. Какие основные функции MPI используются для распределения и сбора данных между процессами?
Для распределения данных между процессами часто используются функции MPI_Scatter и MPI_Scatterv. Для сбора результатов применяется MPI_Gather или MPI_Reduce, в зависимости от задачи. Эти функции упрощают обмен данными и позволяют организовать коллективные операции без ручной передачи сообщений.

6. Как количество процессов MPI влияет на время выполнения программы и почему?
Увеличение количества MPI-процессов может уменьшить время выполнения за счёт параллельной обработки данных. Однако после определённого момента накладные расходы на обмен данными и синхронизацию начинают доминировать. В результате слишком большое число процессов может привести к отсутствию ускорения или даже к замедлению программы.

7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?
Масштабируемость ограничивается затратами на коммуникацию между процессами и синхронизацию. Существенную роль играют пропускная способность сети, задержки передачи данных и неравномерная загрузка процессов. Также ограничения накладывает последовательная часть алгоритма, которая не поддаётся распараллеливанию.

8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?
Распределённые вычисления оправданы для задач с большими объёмами данных и высокой степенью параллелизма. Они особенно эффективны, когда вычислительная нагрузка значительно превышает затраты на обмен данными. Для небольших задач или алгоритмов с частыми синхронизациями распределённый подход может быть неэффективным из-за больших накладных расходов.
